# -*- coding: utf-8 -*-
"""Cohere_Recipe_Gen -Updated.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-yp-ZxKdhrF6upESYqi2Nd5jxcYoyX7Y
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
wilmerarltstrmberg_recipe_dataset_over_2m_path = kagglehub.dataset_download('wilmerarltstrmberg/recipe-dataset-over-2m')

print('Data source import complete.')

!pip install kaggle
!pip install cohere

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import ast

# Download the dataset using kagglehub
wilmerarltstrmberg_recipe_dataset_over_2m_path = kagglehub.dataset_download('wilmerarltstrmberg/recipe-dataset-over-2m')

print('Data source import complete.')

# Construct the full path to the CSV file within the downloaded dataset directory
# The downloaded dataset structure usually mirrors the original.
dataset_file_path = f"{wilmerarltstrmberg_recipe_dataset_over_2m_path}/recipes_data.csv"

# Load the dataset using the correct local path
# Load the dataset from the downloaded path
df = pd.read_csv(dataset_file_path)

# Check the original dataset size
print("Original dataset size:", len(df))

# Randomly select 15,000 rows
selected_data = df.sample(n=15000, random_state=42)

# Save the selected data to a new CSV file (inside working directory)
# This part is fine as it saves to the current working directory.
selected_data.to_csv('selected_15k_rows.csv', index=False)

# Check the size of the selected data
print("Selected data size:", len(selected_data))

# Print the first few rows
print("\nFirst few rows of selected data:")
print(selected_data.head())

# Basic info
print("\nDataset Info:")
selected_data.info()

# Check missing values
print("\nMissing Values:")
print(selected_data.isnull().sum())

# Fill missing categorical values correctly (future-proof way)
cat_cols = ['source', 'site']
df.fillna({col: 'Unknown' for col in cat_cols}, inplace=True)

# Verify
print("\nMissing Values After Handling:")
print(df.isnull().sum())
# Fill missing categorical values correctly (future-proof way)
cat_cols = ['source', 'site']
df.fillna({col: 'Unknown' for col in cat_cols}, inplace=True)

# Verify
print("\nMissing Values After Handling:")
print(df.isnull().sum())

"""# Catagorical Data Analysis"""

plt.figure(figsize=(10,6))
sns.countplot(y='source', data=df, order=df['source'].value_counts().index)
plt.title('Recipe Distribution by Source')
plt.show()

# Group rare sites
site_counts = df['site'].value_counts()
threshold = 50  # Sites with <50 recipes become "Other"
df['site'] = df['site'].apply(lambda x: x if site_counts.get(x,0) >= threshold else 'Other')

plt.figure(figsize=(12,6))
sns.countplot(y='site', data=df, order=df['site'].value_counts().index)
plt.title('Recipe Distribution by Site (Grouped)')
plt.show()

# One-hot encode source
df = pd.get_dummies(df, columns=['source'], prefix='src')

# Frequency encoding for site
site_freq = df['site'].value_counts(normalize=True)
df['site_encoded'] = df['site'].map(site_freq)
df.drop('site', axis=1, inplace=True)

# Convert string representation to actual list
df['NER'] = df['NER'].apply(ast.literal_eval)

# Analyze NER entities
ner_counts = Counter()
df['NER'].apply(lambda x: ner_counts.update(x))

# Create top 20 NER features
top_ner = [entity for entity, count in ner_counts.most_common(20)]
for entity in top_ner:
    df[f'ner_{entity}'] = df['NER'].apply(lambda x: 1 if entity in x else 0)

df.drop('NER', axis=1, inplace=True)

# Analyze ingredients/directions length
df['ingredients_count'] = df['ingredients'].apply(lambda x: len(ast.literal_eval(x)))
df['directions_length'] = df['directions'].apply(lambda x: len(ast.literal_eval(x)))

print("\nText Statistics:")
print(df[['ingredients_count', 'directions_length']].describe())

# Plot distributions
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
sns.histplot(df['ingredients_count'], bins=30)
plt.title('Ingredients Count Distribution')

plt.subplot(1,2,2)
sns.histplot(df['directions_length'], bins=30)
plt.title('Directions Length Distribution')
plt.show()

# Check exact duplicates
print(f"\nNumber of exact duplicates: {df.duplicated().sum()}")

# Check title duplicates
print(f"Number of title duplicates: {df['title'].duplicated().sum()}")

print("\nFinal Dataset Columns:")
print(df.columns)
print("\nFinal Dataset Shape:", df.shape)

# After sampling the data
df = selected_data.copy()

print("Working dataset shape:", df.shape)

!pip install cohere
import cohere
import pandas as pd

# Authenticate
co = cohere.Client("TjRlGT2z3C8nqBlNysvvtWYFBw3ynV2ylYDobuUA")

# Load the dataset
df = pd.read_csv('selected_15k_rows.csv')

# Keep rows with non-empty ingredients and directions
df = df.dropna(subset=['ingredients', 'directions'])

# Create prompt → completion structure
finetune_data = pd.DataFrame({
    'prompt': df['title'].str.strip() + " | " + df['ingredients'].str.strip(),
    'completion': df['directions'].str.strip()
})

# Save in JSONL format
finetune_data.to_json('cohere_train_data.jsonl', orient='records', lines=True)

!pip install --upgrade certifi urllib3 pyOpenSSL
import ssl
import certifi
import urllib3

print("SSL Cert Path:", certifi.where())

# Test secure connection
http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED', ca_certs=certifi.where())
r = http.request('GET', 'https://api.cohere.ai/v1')
print("Connection OK:", r.status == 200)

ingredients = "chicken breast, olive oil, garlic, salt, pepper, lemon juice"
cuisine = "Mediterranean"

import cohere
import re

# Initialize Cohere client
co = cohere.Client("TjRlGT2z3C8nqBlNysvvtWYFBw3ynV2ylYDobuUA")

# Basic ingredient and cuisine validators
def is_valid_ingredients(text):
    # Should have at least 2 items, mostly letters
    items = [i.strip() for i in text.split(",")]
    return len(items) >= 2 and all(re.match("^[a-zA-Z\s\-]+$", i) for i in items)

def is_valid_cuisine(text):
    return bool(re.match("^[a-zA-Z\s]+$", text)) and len(text) >= 3

# Get user input
ingredients = input("Enter available ingredients (comma-separated): ").strip()
cuisine = input("Enter cuisine type (e.g., Italian, Indian, Mediterranean): ").strip()

# Validate input
if not is_valid_ingredients(ingredients):
    print("\n❌ Error: Please enter at least two valid ingredients, separated by commas (e.g., 'Chicken, Rice').")
elif not is_valid_cuisine(cuisine):
    print("\n❌ Error: Please enter a valid cuisine type (e.g., 'Indian', 'Italian').")
else:
    # Format prompt
    def format_prompt(ingredients, cuisine):
        return (
            f"You are a professional chef. Using the following ingredients, write a detailed "
            f"{cuisine} recipe.\n\n"
            f"Ingredients: {ingredients}\n\n"
            f"Write clear, numbered, step-by-step cooking instructions only.\n"
            f"Include at least 8 detailed steps.\n\n"
            f"Steps:"
        )

    prompt = format_prompt(ingredients, cuisine)

    # Generate response
    response = co.generate(
        model="command-r-plus",
        prompt=prompt,
        max_tokens=750,
        temperature=0.4,
    )

    # Output
    print("\n✅ Generated Cooking Instructions:\n")
    print(response.generations[0].text.strip())